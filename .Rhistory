pars = c("(Intercept)", "studytime", "failures", "absences", "sigma"),
pch = 20,
cex = 0.4)
summary(advanced_hierarchical_model)
posterior_summary <- as.data.frame(posterior_interval(advanced_hierarchical_model))
print(posterior_summary)
# Global PPC
pp_check(advanced_hierarchical_model) +
ggtitle("Global Posterior Predictive Check for Hierarchical Model")
# Group-level PPC
pp_check(advanced_hierarchical_model, group = "school") +
ggtitle("Posterior Predictive Check by School")
# library(shinystan)
# launch_shinystan(advanced_hierarchical_model)
# posterior <- as.matrix(advanced_hierarchical_model)
# divergences <- sum(attr(posterior, "sampler_params")$divergent__)
# print(divergences)
# Install and load rstanarm if needed
if (!requireNamespace("rstanarm", quietly = TRUE)) install.packages("rstanarm")
library(rstanarm)
# Bayesian interaction model
bayesian_interaction_model <- stan_glm(
G3 ~ studytime * sex + failures + absences,
data = d1,
family = gaussian(),
prior_intercept = normal(10, 5),
prior = normal(0, 2.5),
prior_aux = cauchy(0, 2),
chains = 4,
iter = 2000,
seed = 123
)
# Compute WAIC for the Bayesian models
waic_one_param <- waic(bayesian_interaction_model)
waic_hierarchical <- waic(advanced_hierarchical_model)
# Print WAIC results
print(waic_one_param)
print(waic_hierarchical)
# Compute LOO for both models
loo_one_param <- loo(bayesian_interaction_model)
loo_hierarchical <- loo(advanced_hierarchical_model)
# Compare models using loo_compare
loo_comparison <- loo_compare(loo_one_param, loo_hierarchical)
# Print LOO comparison results
print(loo_comparison)
# Posterior predictive checks for the interaction model
pp_check(bayesian_interaction_model)
# Posterior predictive checks for the hierarchical model
pp_check(advanced_hierarchical_model)
# Extract posterior samples for random effects
library(bayesplot)
posterior_samples <- as.data.frame(advanced_hierarchical_model)
# Visualize posterior for group-level intercepts (schools)
mcmc_areas(
posterior_samples,
pars = c("b[school_A]", "b[school_B]"),
prob = 0.8
) +
labs(title = "Posterior Distributions for School-Level Effects",
x = "Effect Size", y = "Density")
mcmc_areas(
posterior_samples,
pars = c("b[school_A]", "b[school_B]"),
prob = 0.8
) +
labs(title = "Posterior Distributions for School-Level Effects",
x = "Effect Size", y = "Density")
# Extract posterior samples for random effects
library(bayesplot)
posterior_samples <- as.data.frame(advanced_hierarchical_model)
# Visualize posterior for group-level intercepts (schools)
mcmc_areas(
advanced_hierarchical_model,
pars = c("b[studytime:school_A]", "b[studytime:school_B]"),
prob = 0.8
) +
labs(title = "Posterior Distributions for School-Level Effects",
x = "Effect Size", y = "Density")
# Extract posterior samples for random effects
library(bayesplot)
posterior_samples <- as.data.frame(advanced_hierarchical_model)
# Visualize posterior for group-level intercepts (schools)
mcmc_areas(
posterior_samples,
regex_pars = "b\\[.*:school.*\\]",
prob = 0.8
) +
labs(title = "Posterior Distributions for School-Level Effects",
x = "Effect Size", y = "Density")
posterior_samples <- as.data.frame(advanced_hierarchical_model)
colnames(posterior_samples) # List all parameter names
# Extract posterior samples for random effects
library(bayesplot)
posterior_samples <- as.data.frame(advanced_hierarchical_model)
colnames(posterior_samples) # List all parameter names
# Visualize posterior for group-level intercepts (schools)
mcmc_areas(
posterior_samples,
pars = c("b[studytime:school_A]", "b[studytime:school_B]"),
prob = 0.8
) +
labs(title = "Posterior Distributions for School-Level Effects",
x = "Effect Size", y = "Density")
colnames(posterior_samples) # List all parameter names
# Extract posterior samples for random effects
library(bayesplot)
posterior_samples <- as.data.frame(advanced_hierarchical_model)
colnames(posterior_samples) # List all parameter names
# Visualize posterior for group-level intercepts (schools)
mcmc_areas(
posterior_samples,
pars = c("b[studytime school:GP]", "b[studytime school:MS]"),
prob = 0.8
) +
labs(
title = "Posterior Distributions for School-Level Effects",
x = "Effect Size",
y = "Density"
)
# Prepare data for Stan
X <- as.matrix(fact_data[, c("temperature", "ratio", "contact",
"temperature_sq", "ratio_sq", "contact_sq",
"temperature_ratio", "ratio_contact", "temperature_contact")])
y <- fact_data$conversion
stan_data <- list(
N = nrow(fact_data),
K = ncol(X),
X = X,
y = y
)
# Fit Bayesian model
fit <- stan(model_code = "Q2_Bayesian_Model.stan", data = stan_data, iter = 2000, chains = 4)
# Prepare data for Stan
X <- as.matrix(fact_data[, c("temperature", "ratio", "contact",
"temperature_sq", "ratio_sq", "contact_sq",
"temperature_ratio", "ratio_contact", "temperature_contact")])
y <- fact_data$conversion
stan_data <- list(
N = nrow(fact_data),
K = ncol(X),
X = X,
y = y
)
# Fit Bayesian model
fit <- stan(file = "Q2_Bayesian_Model.stan", data = stan_data, iter = 2000, chains = 4)
print(fit)
# install.packages("rstan", repos = "https://cloud.r-project.org/")
library(rstan)
# Load data
fact_data <- read.csv("factorial_data.csv")
# Prepare data
fact_data$temperature_sq <- fact_data$temperature^2
fact_data$ratio_sq <- fact_data$ratio^2
fact_data$contact_sq <- fact_data$contact^2
fact_data$temperature_ratio <- fact_data$temperature * fact_data$ratio
fact_data$ratio_contact <- fact_data$ratio * fact_data$contact
fact_data$temperature_contact <- fact_data$temperature * fact_data$contact
# Fit OLS model
ols_model <- lm(conversion ~ temperature + ratio + contact +
temperature_sq + ratio_sq + contact_sq +
temperature_ratio + ratio_contact + temperature_contact,
data = fact_data)
summary(ols_model)
# Prepare data for Stan
X <- as.matrix(fact_data[, c("temperature", "ratio", "contact",
"temperature_sq", "ratio_sq", "contact_sq",
"temperature_ratio", "ratio_contact", "temperature_contact")])
y <- fact_data$conversion
stan_data <- list(
N = nrow(fact_data),
K = ncol(X),
X = X,
y = y
)
# Fit Bayesian model
fit <- stan(file = "Q2_Bayesian_Model.stan", data = stan_data, iter = 2000, chains = 4)
print(fit)
fit_t4 <- stan(model_code = "Q2-Bayesian-Model-t4-prior.stan", data = stan_data, iter = 2000, chains = 4)
# install.packages("rstan", repos = "https://cloud.r-project.org/")
library(rstan)
# Load data
fact_data <- read.csv("factorial_data.csv")
# Prepare data
fact_data$temperature_sq <- fact_data$temperature^2
fact_data$ratio_sq <- fact_data$ratio^2
fact_data$contact_sq <- fact_data$contact^2
fact_data$temperature_ratio <- fact_data$temperature * fact_data$ratio
fact_data$ratio_contact <- fact_data$ratio * fact_data$contact
fact_data$temperature_contact <- fact_data$temperature * fact_data$contact
# Fit OLS model
ols_model <- lm(conversion ~ temperature + ratio + contact +
temperature_sq + ratio_sq + contact_sq +
temperature_ratio + ratio_contact + temperature_contact,
data = fact_data)
summary(ols_model)
# Prepare data for Stan
X <- scale(fact_data[, c("temperature", "ratio", "contact",
"temperature_sq", "ratio_sq", "contact_sq",
"temperature_ratio", "ratio_contact", "temperature_contact")])
y <- fact_data$conversion
stan_data <- list(
N = nrow(fact_data),
K = ncol(X),
X = X,
y = y
)
# Fit Bayesian model
fit <- stan(file = "Q2_Bayesian_Model.stan", data = stan_data, iter = 8000, chains = 4,
control = list(adapt_delta = 0.99, max_treedepth = 15))
print(fit)
pairs(fit, pars = c("beta[1]", "beta[2]", "sigma"))
summary(fit) # R-hat and ESS for all parameters
posterior <- as.array(fit)
mcmc_trace(posterior, pars = c("beta[1]", "beta[2]", "sigma")) # Trace plots
mcmc_pairs(posterior, pars = c("beta[1]", "beta[2]")) # Joint posterior diagnostics
fit_t4 <- stan(model_code = "Q2-Bayesian-Model-t4-prior.stan", data = stan_data, iter = 2000, chains = 4)
fit_t4 <- stan(file = "Q2-Bayesian-Model-t4-prior.stan", data = stan_data, iter = 2000, chains = 4)
print(fit_t4)
library(glmnet)
# Simulated example dataset
set.seed(123)
n <- 100
data <- data.frame(
ratio = rnorm(n, 1300, 100),
contact = runif(n, 5, 23),
conversion = rnorm(n, 0.03, 0.01),
y = rnorm(n, 40, 10)
)
# Add interaction and squared terms
data$ratio_sq <- data$ratio^2
data$contact_sq <- data$contact^2
data$conversion_sq <- data$conversion^2
data$ratiocontact <- data$ratio * data$contact
data$contactconversion <- data$contact * data$conversion
data$ratioconversion <- data$ratio * data$conversion
# Prepare matrix for glmnet
X <- as.matrix(data[, c("ratio", "contact", "conversion", "ratio_sq", "contact_sq", "conversion_sq", "ratiocontact", "contactconversion", "ratioconversion")])
y <- data$y
# Fit ridge regression
ridge_model <- glmnet(X, y, alpha = 0)  # alpha = 0 for ridge regression
ridge_cv <- cv.glmnet(X, y, alpha = 0)  # Cross-validation to find best lambda
ridge_best_lambda <- ridge_cv$lambda.min
# Extract coefficients at best lambda
ridge_coefficients <- coef(ridge_cv, s = ridge_best_lambda)
print(ridge_coefficients)
# install.packages("brms")
library(brms)
# Fitting a Bayesian regression model
posterior_model <- brm(
y ~ ratio + contact + conversion + ratio_sq + contact_sq + conversion_sq + ratiocontact + contactconversion + ratioconversion,
data = data,
family = gaussian()
)
# Converting to array
posterior_array <- as.array(posterior_model)
# inspecting posterior samples
summary(posterior_array)
# Fit LASSO regression
lasso_model <- glmnet(X, y, alpha = 1)  # alpha = 1 for LASSO
lasso_cv <- cv.glmnet(X, y, alpha = 1)  # Cross-validation to select lambda
lasso_best_lambda <- lasso_cv$lambda.min
lasso_coefficients <- coef(lasso_cv, s = lasso_best_lambda)
lasso_coefficients
# install.packages("kernlab")
library(kernlab)
# Fit Gaussian Process model
gpr_model <- gausspr(X, y, kernel = "rbfdot")
gpr_predictions <- predict(gpr_model, X)
# Compare predicted and observed values
pred_obs <- data.frame(Observed = y, Predicted = gpr_predictions)
print (pred_obs)
# colnames(pred_obs)
# Error metrics
mse <- mean((pred_obs$Observed - pred_obs$Predicted)^2)
rmse <- sqrt(mse)
mae <- mean(abs(pred_obs$Observed - pred_obs$Predicted))
r_squared <- 1 - (sum((pred_obs$Observed - pred_obs$Predicted)^2) / sum((pred_obs$Observed - mean(pred_obs$Observed))^2))
cat("MSE:", mse, "\nRMSE:", rmse, "\nMAE:", mae, "\nR-squared:", r_squared)
# Visualization
library(ggplot2)
ggplot(pred_obs, aes(x = Observed, y = Predicted)) +
geom_point(color = "blue", size = 2.5) +
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
labs(title = "Observed vs Predicted Values", x = "Observed", y = "Predicted") +
theme_minimal()
# Residuals
pred_obs$Residuals <- pred_obs$Observed - pred_obs$Predicted
# Plot residuals
ggplot(pred_obs, aes(x = Observed, y = Residuals)) +
geom_point(color = "purple", size = 2.5) +
geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
labs(title = "Residuals vs Observed Values", x = "Observed", y = "Residuals") +
theme_minimal()
# install.packages("rstan", repos = "https://cloud.r-project.org/")
library(rstan)
# Load data
fact_data <- read.csv("factorial_data.csv")
# Prepare data
fact_data$temperature_sq <- fact_data$temperature^2
fact_data$ratio_sq <- fact_data$ratio^2
fact_data$contact_sq <- fact_data$contact^2
fact_data$temperature_ratio <- fact_data$temperature * fact_data$ratio
fact_data$ratio_contact <- fact_data$ratio * fact_data$contact
fact_data$temperature_contact <- fact_data$temperature * fact_data$contact
# Fit OLS model
ols_model <- lm(conversion ~ temperature + ratio + contact +
temperature_sq + ratio_sq + contact_sq +
temperature_ratio + ratio_contact + temperature_contact,
data = fact_data)
summary(ols_model)
# Prepare data for Stan
X <- scale(fact_data[, c("temperature", "ratio", "contact",
"temperature_sq", "ratio_sq", "contact_sq",
"temperature_ratio", "ratio_contact", "temperature_contact")])
y <- fact_data$conversion
stan_data <- list(
N = nrow(fact_data),
K = ncol(X),
X = X,
y = y
)
# Fit Bayesian model
fit <- stan(file = "Q2_Bayesian_Model.stan", data = stan_data, iter = 8000, chains = 4,
control = list(adapt_delta = 0.99, max_treedepth = 15))
print(fit)
pairs(fit, pars = c("beta[1]", "beta[2]", "sigma"))
summary(fit) # R-hat and ESS for all parameters
posterior <- as.array(fit)
mcmc_trace(posterior, pars = c("beta[1]", "beta[2]", "sigma")) # Trace plots
mcmc_pairs(posterior, pars = c("beta[1]", "beta[2]")) # Joint posterior diagnostics
mcmc_pairs(posterior, pars = c("beta[1]", "beta[2]", pch = 19, cex = 0.4)) # Joint posterior diagnostics
mcmc_pairs(posterior, pars = c("beta[1]", "beta[2]")) # Joint posterior diagnostics
fit_t4 <- stan(file = "Q2-Bayesian-Model-t4-prior.stan",
data = stan_data,
iter = 8000,
chains = 4,
control = list(adapt_delta = 0.99, max_treedepth = 15))
print(fit_t4)
pairs(fit_t4, pars = c("beta[1]", "beta[2]", "sigma"))
fit_t4 <- stan(file = "Q2-Bayesian-Model-t4-prior.stan",
data = stan_data,
iter = 8000,
chains = 4,
control = list(adapt_delta = 0.9999, max_treedepth = 15))
print(fit_t4)
pairs(fit_t4, pars = c("beta[1]", "beta[2]", "sigma"))
fit_t4 <- stan(file = "Q2-Bayesian-Model-t4-prior.stan",
data = stan_data,
iter = 8000,
chains = 4,
control = list(adapt_delta = 0.9999, max_treedepth = 15))
print(fit_t4)
pairs(fit_t4, pars = c("beta[1]", "beta[2]", "sigma"))
posterior <- as.array(fit_t4)
mcmc_trace(posterior, pars = c("beta[1]", "beta[2]", "sigma"))
library(glmnet)
# Simulated example dataset
set.seed(123)
n <- 100
data <- data.frame(
ratio = rnorm(n, 1300, 100),
contact = runif(n, 5, 23),
conversion = rnorm(n, 0.03, 0.01),
y = rnorm(n, 40, 10)
)
# Add interaction and squared terms
data$ratio_sq <- data$ratio^2
data$contact_sq <- data$contact^2
data$conversion_sq <- data$conversion^2
data$ratiocontact <- data$ratio * data$contact
data$contactconversion <- data$contact * data$conversion
data$ratioconversion <- data$ratio * data$conversion
# Prepare matrix for glmnet
X <- as.matrix(data[, c("ratio", "contact", "conversion", "ratio_sq", "contact_sq", "conversion_sq", "ratiocontact", "contactconversion", "ratioconversion")])
y <- data$y
# Fit ridge regression
ridge_model <- glmnet(X, y, alpha = 0)  # alpha = 0 for ridge regression
ridge_cv <- cv.glmnet(X, y, alpha = 0)  # Cross-validation to find best lambda
ridge_best_lambda <- ridge_cv$lambda.min
# Extract coefficients at best lambda
ridge_coefficients <- coef(ridge_cv, s = ridge_best_lambda)
print(ridge_coefficients)
# install.packages("brms")
library(brms)
# Fitting a Bayesian regression model
posterior_model <- brm(
y ~ ratio + contact + conversion + ratio_sq + contact_sq + conversion_sq + ratiocontact + contactconversion + ratioconversion,
data = data,
family = gaussian()
)
# Converting to array
posterior_array <- as.array(posterior_model)
# inspecting posterior samples
summary(posterior_array)
# Fit LASSO regression
lasso_model <- glmnet(X, y, alpha = 1)  # alpha = 1 for LASSO
lasso_cv <- cv.glmnet(X, y, alpha = 1)  # Cross-validation to select lambda
lasso_best_lambda <- lasso_cv$lambda.min
lasso_coefficients <- coef(lasso_cv, s = lasso_best_lambda)
lasso_coefficients
# install.packages("kernlab")
library(kernlab)
# Fit Gaussian Process model
gpr_model <- gausspr(X, y, kernel = "rbfdot")
gpr_predictions <- predict(gpr_model, X)
# Compare predicted and observed values
pred_obs <- data.frame(Observed = y, Predicted = gpr_predictions)
print (pred_obs)
# colnames(pred_obs)
# Error metrics
mse <- mean((pred_obs$Observed - pred_obs$Predicted)^2)
rmse <- sqrt(mse)
mae <- mean(abs(pred_obs$Observed - pred_obs$Predicted))
r_squared <- 1 - (sum((pred_obs$Observed - pred_obs$Predicted)^2) / sum((pred_obs$Observed - mean(pred_obs$Observed))^2))
cat("MSE:", mse, "\nRMSE:", rmse, "\nMAE:", mae, "\nR-squared:", r_squared)
# Visualization
library(ggplot2)
ggplot(pred_obs, aes(x = Observed, y = Predicted)) +
geom_point(color = "blue", size = 2.5) +
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
labs(title = "Observed vs Predicted Values", x = "Observed", y = "Predicted") +
theme_minimal()
# install.packages("rstan", repos = "https://cloud.r-project.org/")
library(rstan)
# Load data
fact_data <- read.csv("factorial_data.csv")
# Prepare data
fact_data$temperature_sq <- fact_data$temperature^2
fact_data$ratio_sq <- fact_data$ratio^2
fact_data$contact_sq <- fact_data$contact^2
fact_data$temperature_ratio <- fact_data$temperature * fact_data$ratio
fact_data$ratio_contact <- fact_data$ratio * fact_data$contact
fact_data$temperature_contact <- fact_data$temperature * fact_data$contact
# Fit OLS model
ols_model <- lm(conversion ~ temperature + ratio + contact +
temperature_sq + ratio_sq + contact_sq +
temperature_ratio + ratio_contact + temperature_contact,
data = fact_data)
summary(ols_model)
# Prepare data for Stan
X <- scale(fact_data[, c("temperature", "ratio", "contact",
"temperature_sq", "ratio_sq", "contact_sq",
"temperature_ratio", "ratio_contact", "temperature_contact")])
y <- fact_data$conversion
stan_data <- list(
N = nrow(fact_data),
K = ncol(X),
X = X,
y = y
)
# Fit Bayesian model
fit <- stan(file = "Q2_Bayesian_Model.stan", data = stan_data, iter = 8000, chains = 4,
control = list(adapt_delta = 0.99, max_treedepth = 15))
print(fit)
pairs(fit, pars = c("beta[1]", "beta[2]", "sigma"))
summary(fit) # R-hat and ESS for all parameters
posterior <- as.array(fit)
mcmc_trace(posterior, pars = c("beta[1]", "beta[2]", "sigma")) # Trace plots
mcmc_pairs(posterior, pars = c("beta[1]", "beta[2]")) # Joint posterior diagnostics
fit_t4 <- stan(file = "Q2-Bayesian-Model-t4-prior.stan",
data = stan_data,
iter = 8000,
chains = 4,
control = list(adapt_delta = 0.9999, max_treedepth = 15))
print(fit_t4)
pairs(fit_t4, pars = c("beta[1]", "beta[2]", "sigma"))
posterior <- as.array(fit_t4)
mcmc_trace(posterior, pars = c("beta[1]", "beta[2]", "sigma"))
library(glmnet)
# Simulated example dataset
set.seed(123)
n <- 100
data <- data.frame(
ratio = rnorm(n, 1300, 100),
contact = runif(n, 5, 23),
conversion = rnorm(n, 0.03, 0.01),
y = rnorm(n, 40, 10)
)
# Add interaction and squared terms
data$ratio_sq <- data$ratio^2
data$contact_sq <- data$contact^2
data$conversion_sq <- data$conversion^2
data$ratiocontact <- data$ratio * data$contact
data$contactconversion <- data$contact * data$conversion
data$ratioconversion <- data$ratio * data$conversion
# Prepare matrix for glmnet
X <- as.matrix(data[, c("ratio", "contact", "conversion", "ratio_sq", "contact_sq", "conversion_sq", "ratiocontact", "contactconversion", "ratioconversion")])
y <- data$y
# Fit ridge regression
ridge_model <- glmnet(X, y, alpha = 0)  # alpha = 0 for ridge regression
ridge_cv <- cv.glmnet(X, y, alpha = 0)  # Cross-validation to find best lambda
ridge_best_lambda <- ridge_cv$lambda.min
# Extract coefficients at best lambda
ridge_coefficients <- coef(ridge_cv, s = ridge_best_lambda)
print(ridge_coefficients)
# install.packages("brms")
library(brms)
# Fitting a Bayesian regression model
posterior_model <- brm(
y ~ ratio + contact + conversion + ratio_sq + contact_sq + conversion_sq + ratiocontact + contactconversion + ratioconversion,
data = data,
family = gaussian()
)
# install.packages("rstan", repos = "https://cloud.r-project.org/")
library(rstan)
library(mcmc)
library(MCMCpack)
pairs(fit, pars = c("beta[1]", "beta[2]", "sigma"))
summary(fit) # R-hat and ESS for all parameters
posterior <- as.array(fit)
mcmc_trace(posterior, pars = c("beta[1]", "beta[2]", "sigma")) # Trace plots
mcmc_pairs(posterior, pars = c("beta[1]", "beta[2]")) # Joint posterior diagnostics
